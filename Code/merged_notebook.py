# -*- coding: utf-8 -*-
"""Merged Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1txrIsrAADiwkeD8VfOG1Xp4nHbhQAUL1
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Reshape, add
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose
from tensorflow.keras import regularizers
from skimage.util import random_noise
import cv2
import keras
import os
from PIL import Image
import datetime
from tensorflow.keras.callbacks import TensorBoard
from keras.models import model_from_json

PATH=r'B:\Major\finalDataset\clean'
PATH2=r'B:\Major\finalDataset\smudged'
directory=os.listdir(PATH)
directory2=os.listdir(PATH2)
directory.sort()
directory2.sort()

X_train=[]
for file in directory:
    img=cv2.imread("{}/{}".format(PATH,file),0)
    # print(img)
    try:
      # img=cv2.resize(img)
      X_train.append(img)
    except:
      pass

X_train=np.array(X_train)
X_train.shape

y_train=[]
for file in directory2:
    # print(file)
    img=cv2.imread("{}/{}".format(PATH2,file),0)
    # print(img)
    try:
      # img=cv2.resize(img)
      y_train.append(img)
    except:
      pass

y_train=np.array(y_train)
y_train.shape

X_train = X_train/255.0
y_train=y_train/255.0

shape=X_train.shape

X_train=X_train.reshape(shape[0],shape[1],shape[2],1)
y_train=y_train.reshape(shape[0],shape[1],shape[2],1)

layers=[2,3]
nodes=[32,64,128]

for l in layers:
  model=Sequential()
  input_img = keras.Input(shape=(256, 256, 1))
    #encoder
  for n1 in range(0,3):
    x = Conv2D(nodes[n1], (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2), padding='same')(x)
    # print(nodes[n1])
    for n2 in range(0,3):
      y = Conv2D(nodes[n2], (3, 3), activation='relu', padding='same')(x)
      y = MaxPooling2D((2, 2), padding='same')(y)
      if l==3:
        for n3 in range(0,3):
          z = Conv2D(nodes[n3], (3, 3), activation='relu', padding='same')(y)
          z = MaxPooling2D((2, 2), padding='same')(z)
          z = Conv2D(nodes[n3], (3, 3), activation='relu', padding='same')(z)
          z = UpSampling2D((2, 2))(z)
          z = Conv2D(nodes[n2], (3, 3), activation='relu', padding='same')(z)
          z = UpSampling2D((2, 2))(z)
          z = Conv2D(nodes[n1], (3, 3), activation='relu', padding='same')(z)
          z = UpSampling2D((2, 2))(z)
          decoded = Conv2D(1, (3, 3), activation='sigmoid',padding='same')(z)

          autoencoder = keras.Model(input_img, decoded)
          autoencoder.compile(optimizer='adamax', loss='binary_crossentropy')
          autoencoder.summary()
          autoencoder.fit(y_train[350:500], X_train[350:500],epochs=5,batch_size=16,shuffle=True)
      else:
        z = Conv2D(nodes[n2], (3, 3), activation='relu', padding='same')(y)
        z = UpSampling2D((2, 2))(z)
        a = Conv2D(nodes[n1], (3, 3), activation='relu', padding='same')(z)
        a = UpSampling2D((2, 2))(a)
        decoded = Conv2D(1, (3, 3), activation='sigmoid',padding='same')(a)

        autoencoder = keras.Model(input_img, decoded)
        autoencoder.compile(optimizer='adamax', loss='mse')
        autoencoder.summary()
        autoencoder.fit(y_train[350:500], X_train[350:500],epochs=5,batch_size=16,shuffle=True)

tf.__version__

X_train.shape

y_train.shape

model=Sequential()

from time import time
from keras.utils.vis_utils import plot_model
from keras.utils.vis_utils import model_to_dot

tensorboard = TensorBoard(log_dir='B:\Major\git code\ImageProcessing\logs\{}'.format(time()))

input_img = keras.Input(shape=(256, 256, 1))
    #encoder
x = Conv2D(32, (3, 3), activation='relu', padding='same', name = 'Conv_1')(input_img)
x = MaxPooling2D((2, 2), padding='same', name = 'MaxPool_1')(x)
x = Conv2D(64, (3, 3), activation='relu', padding='same', name = 'Conv_2')(x)
encoded = MaxPooling2D((2, 2), padding='same', name = 'MaxPool_2')(x)
#decoder
x = Conv2D(64, (3, 3), activation='relu', padding='same', name = 'Conv_3')(encoded)
x = UpSampling2D((2, 2), name = 'UpSample_1')(x)
x = Conv2D(32, (3, 3), activation='relu', padding='same', name = 'Conv_4')(x)
x = UpSampling2D((2, 2), name = 'UpSample_2')(x)
decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)

autoencoder = keras.Model(input_img, decoded)
autoencoder.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy', 'mse', 'mae','Precision'])
autoencoder.summary()

plot_model(autoencoder, to_file=r'B:\Major\git code\ImageProcessing\Models\model_plot.png', show_shapes=True, show_layer_names=True)

autoencoder.fit(y_train, X_train,
                epochs=50,
                batch_size=16,
                shuffle=True,
                callbacks=[tensorboard])

json_model = autoencoder.to_json()
json_file = open(r'B:\Major\git code\ImageProcessing\Models\SmudgeRemovalV6\smudge_autoencoderV7.json', 'w')
json_file.write(json_model)
# saving model weights
autoencoder.save_weights(r'B:\Major\git code\ImageProcessing\Models\SmudgeRemovalV6\smudge_autoencoder_weightsV7.h5', 'w')

PATH=r'B:\Major\validationDataset\validationDataset\clean'
PATH2=r'B:\Major\validationDataset\validationDataset\smudged'
directory=os.listdir(PATH)
directory2=os.listdir(PATH2)
directory.sort()
directory2.sort()

X_train=[]
for file in directory:
    img=cv2.imread("{}/{}".format(PATH,file),0)
    try:
      X_train.append(img)
    except:
      pass

y_train=[]
for file in directory:
    img=cv2.imread("{}/{}".format(PATH2,file),0)
    try:
      y_train.append(img)
    except:
      pass

plt.imshow(X_train[0])

plt.imshow(y_train[0])

def apply_unsharpen(image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    image = Image.fromarray(image.astype('uint8'))
    new_image = image.filter(ImageFilter.UnsharpMask(radius=1, percent=150))
    new_image = np.array(new_image)
    return new_image

def apply_gaussian_unsharpen(image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    figure_size = 9
    image = cv2.GaussianBlur(image, (figure_size, figure_size),0)
    image2 = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)
#     image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)
    image2 = Image.fromarray(image2.astype('uint8'))
    new_image = image2.filter(ImageFilter.UnsharpMask(radius=2, percent=150))
    return np.array(new_image)

def apply_laplacian(image):
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
    image = cv2.filter2D(image, -1, kernel)
    return image

def apply_gamma(image):
    k=1.8
    image = 255 * (image/255)**k
    return image

# for i in range(0, len(y_train)):
#     y_train[i] = apply_unsharpen(y_train[i])
#     y_train[i] = apply_gaussian_unsharpen(y_train[i])
#     y_train[i] = apply_laplacian(y_train[i])
#     y_train[i] = apply_gamma(y_train[i])
#     y_train[i] = cv2.cvtColor(y_train[i], cv2.COLOR_BGR2GRAY)
plt.imshow(y_train[0])

X_train=np.array(X_train)
y_train=np.array(y_train)
y_train.shape

X_train = X_train/255.0
y_train = y_train/255.0

shape=X_train.shape
X_train=X_train.reshape(shape[0],shape[1],shape[2],1)
y_train=y_train.reshape(shape[0],shape[1],shape[2],1)

PATH3=r'B:\Major\model'
model = 'smudge_autoencoderV7.json'
weight = 'smudge_autoencoder_weightsV7.h5'

json_file = open(r'{}\{}'.format(PATH3, model), 'r')
json_model = model_from_json(json_file.read())
json_model.load_weights(r'{}\{}'.format(PATH3, weight))

json_model.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy', 'mse', 'mae','Precision'])

result = json_model.evaluate(y_train, X_train, batch_size=1)

test_image = json_model.predict(y_train[0].reshape(1,256,256,1)).reshape(256, 256)

cv2.imwrite(r'B:\Major\datast\filter_test\vt1.png'.format(PATH), test_image*255)
plt.imshow(test_image)

PATH=r'B:\Major\model'
os.listdir(PATH)

PATH2=r'B:\Major\datast'
os.listdir(PATH2)

PATH3=r'B:\Major\datast\output'

model = 'smudge_autoencoderV2.json'
weight = 'smudge_autoencoder_weightsV2.h5'

slice_size = 256
input_file_name = 'test9.png'
print("{}\{}".format(PATH2, input_file_name))

img = cv2.imread("{}\{}".format(PATH2, input_file_name), 0)
plt.imshow(img)
v_res = img.shape[0]
h_res = img.shape[1]
img.shape

def apply_filter(image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    figure_size = 9
    image = cv2.GaussianBlur(image, (figure_size, figure_size),0)

    image2 = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)
    image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)
    image2 = Image.fromarray(image2.astype('uint8'))

    new_image = image2.filter(ImageFilter.UnsharpMask(radius=2, percent=150))
    new_image = np.array(new_image)
    return new_image

def apply_gamma(image):
    k=1.8
    image = 255 * (image/255)**k
    return image

img = apply_gamma(img)
img

def count_blocks(res, slice_size):
  blocks = 0
  if res % slice_size == 0:
    blocks = int(res/slice_size)
  else:
    blocks = (int(res/slice_size)) + 1
  return blocks

def resizeImage(img, v_res, h_res, slice_size):
  v_res = count_blocks(v_res, slice_size) * slice_size
  h_res = count_blocks(h_res, slice_size) * slice_size
  img = cv2.resize(img, (h_res, v_res))
  print(v_res)
  print(h_res)
  return img

img = resizeImage(img, v_res, h_res, slice_size)
plt.imshow(img)
img.shape

json_file = open(r'{}\{}'.format(PATH, model), 'r')
json_model = model_from_json(json_file.read())
json_model.load_weights(r'{}\{}'.format(PATH, weight))

column = count_blocks(h_res, slice_size)
rows = count_blocks(v_res, slice_size)
print(column)
print(rows)

normalImg = img
newImg = None

hor_split_image = np.hsplit(normalImg, column)
for i in hor_split_image:
    v_split = np.vsplit(i, rows)
    cleanHor = None
    for j in v_split:
        smallClean = json_model.predict(j.reshape(1,256,256,1)).reshape(256, 256)
        if cleanHor is None:
            cleanHor = smallClean
        else:
            cleanHor = np.concatenate((cleanHor, smallClean), axis=0)
    if newImg is None:
        newImg = cleanHor
    else:
        newImg = np.concatenate((newImg, cleanHor), axis=1)

newImg = newImg.reshape(img.shape[0], img.shape[1])
newImg = cv2.resize(newImg, (h_res, v_res))
plt.imshow(newImg, cmap='gray')

cv2.imwrite(r'{}\output_{}'.format(PATH3, input_file_name), newImg*255)

